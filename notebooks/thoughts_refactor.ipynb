{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import json\n",
    "from threading import Timer\n",
    "from collections import Counter\n",
    "import torch\n",
    "import faiss                 \n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import ollama\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def clean(note):\n",
    "    # remove zero-links\n",
    "    note = re.sub(r'\\[.*\\]', '', note)\n",
    "    # remove tags and headers\n",
    "    note = re.sub(r'\\#.*\\n', '', note)\n",
    "    # remove lines\n",
    "    note = re.sub('---', ' ', note)\n",
    "    # remove **\n",
    "    note = re.sub('\\*', '', note)\n",
    "    \n",
    "    return note\n",
    "\n",
    "def clean_thought(thought):\n",
    "    thought = re.sub(r'\\(http\\S+', '<LINK>', thought)\n",
    "    thought = re.sub(r'http\\S+', '<LINK>', thought)\n",
    "\n",
    "    if thought[:2] == '- ':\n",
    "        thought = thought[2:]\n",
    "\n",
    "    if '<LINK>' in thought:\n",
    "        linkless = re.sub('<LINK>', '', thought)\n",
    "        linkless = re.sub('[^a-zA-Zа-яА-Я ]', '',  linkless)\n",
    "        linkless = linkless.strip()\n",
    "        if len(linkless.split(' ')) < 2:\n",
    "            return ''\n",
    "    \n",
    "    return thought.strip()\n",
    "\n",
    "\n",
    "def filter_thought(thought):\n",
    "    if not thought:\n",
    "        return False\n",
    "    \n",
    "    thought = str(thought)\n",
    "    letters_only = re.sub('[^a-zA-Zа-яА-Я]', '',  thought)\n",
    "    if len(letters_only) < 30:\n",
    "        return False\n",
    "    \n",
    "    words_only = re.sub('[^a-zA-Zа-яА-Я ]', '',  thought)\n",
    "    if len(words_only.split(' ')) < 10:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def find_tags(note):\n",
    "    tags = re.findall(\"\\B(\\#[a-zA-Z]+(\\n|\\ ))\", note)\n",
    "    tags = [t.split(s)[0][1:] for (t, s) in tags]\n",
    "    return tuple(tags)\n",
    "\n",
    "\n",
    "def parse_folder(db_path, len_thr=40):\n",
    "    path, folders, files = next(os.walk(db_path))\n",
    "\n",
    "    subfolder_dbs = []\n",
    "    if len(folders) > 0:\n",
    "        for f in folders:\n",
    "            folder_path = os.path.join(path, f)\n",
    "            folder_db = parse_folder(folder_path, len_thr)\n",
    "            subfolder_dbs += folder_db\n",
    "\n",
    "    db = []\n",
    "    for fn in files:\n",
    "        if '.md' not in fn:\n",
    "            continue\n",
    "\n",
    "        filepath = os.path.join(path, fn)\n",
    "        with open(filepath, 'r') as f:\n",
    "            note = f.read()\n",
    "\n",
    "        if len(note) < len_thr:\n",
    "            continue\n",
    "        cleaned_note = clean(note)\n",
    "        tags = find_tags(note)\n",
    "        sentences = get_sentences(cleaned_note)\n",
    "        paragraphs = get_paragraphs(cleaned_note)\n",
    "        llm_thoughts = llm_get_thoughts(cleaned_note)\n",
    "        note_dict = {'name': fn.split('.md')[0], 'path':filepath, \n",
    "                     'note':note, 'cleaned_note': cleaned_note, \n",
    "                     'llm_thoughts': llm_thoughts, \n",
    "                     'sentences': sentences, \"paragraphs\": paragraphs, \n",
    "                     'tags': tags}\n",
    "        db.append(note_dict)\n",
    "\n",
    "    db = db + subfolder_dbs\n",
    "    return db\n",
    "\n",
    "\n",
    "def get_sentences(note):\n",
    "    sentences = [t for thought in re.split('\\n|\\t', note) for t in nltk.sent_tokenize(thought)]\n",
    "    cleaned = list(map(clean_thought, sentences))\n",
    "    filtered = list(filter(filter_thought, cleaned))\n",
    "    return filtered\n",
    "\n",
    "def get_paragraphs(note):\n",
    "    paragraphs = [p for p in re.split('\\n\\n', note)]\n",
    "    cleaned = list(map(clean_thought, paragraphs))\n",
    "    filtered = list(filter(filter_thought, cleaned))\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def llm(query):\n",
    "    response = ollama.chat(model='llama3',\n",
    "                            messages=[{'role': 'user', \n",
    "                                        'content': query}])\n",
    "    return response['message']['content']\n",
    "\n",
    "def llm_get_thoughts(text):\n",
    "    prompt = '''Summarize the following text in 2-3 sentences, formulate it very concisely. Text: {} Output only the concise summary, 2-3 sentences.'''\n",
    "    query = prompt.format(text)\n",
    "    ans = llm(query)\n",
    "    if '\\n' in ans: \n",
    "        ans = ans.split('\\n')[-1]\n",
    "    thoughts = ans.split('.')\n",
    "    thoughts = list(filter(len, thoughts))\n",
    "    thoughts = [t.strip() for t in thoughts]\n",
    "    return thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_FIELDS = ['cleaned_note', 'sentences', 'paragraphs', 'llm_thoughts']\n",
    "class NoteManager:\n",
    "    def __init__(self, db_path, \n",
    "                        model_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
    "                        device='cpu',\n",
    "                        save_path='../saved',\n",
    "                        batch_size=32,\n",
    "                        from_scratch=False):\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        self.db_path, self.save_path, self.batch_size = db_path, save_path, batch_size\n",
    "        self.init_model(model_name, device)\n",
    "        self.load_db(from_scratch)\n",
    "        self.parse_notes()\n",
    "        # self.start_timer()\n",
    "    \n",
    "    def parse_notes(self):\n",
    "        print(\"### Parsing notes ###\")\n",
    "        loaded = parse_folder(self.db_path, len_thr=40)\n",
    "\n",
    "        self.add_notes(loaded)\n",
    "        self.build_index()\n",
    "        self.embed_database()\n",
    "        self.save()\n",
    "\n",
    "    def add_notes(self, notes):\n",
    "        print(\"### Adding notes ###\")\n",
    "        # Create dictionaries for fast lookups by 'path'\n",
    "        db_dict = {n['path']: n for n in self.db}\n",
    "        loaded_db_dict = {n['path']: n for n in notes}\n",
    "\n",
    "        new_notes = {path: n for path, n in loaded_db_dict.items() if path not in db_dict}\n",
    "        changed_notes = {path: n for path, n in loaded_db_dict.items() if path in db_dict and db_dict[path]['note'] != n['note']}\n",
    "        deleted_note_paths = {path for path in db_dict if path not in loaded_db_dict}\n",
    "\n",
    "        for path in changed_notes:\n",
    "            del db_dict[path]\n",
    "\n",
    "        for path in deleted_note_paths:\n",
    "            del db_dict[path]\n",
    "\n",
    "        # Update database with new notes\n",
    "        self.db = list(db_dict.values()) + list(new_notes.values()) + list(changed_notes.values())\n",
    "    \n",
    "    def build_index(self):\n",
    "        print(\"### Buliding index ###\")\n",
    "        self.f2i = dict()\n",
    "        for field in SEARCH_FIELDS:\n",
    "            note_inds = []\n",
    "            field_inds = []\n",
    "            for note_ind, note in enumerate(self.db):\n",
    "                nf = note[field]\n",
    "                if type(nf) == str:\n",
    "                    note_inds.append(note_ind)\n",
    "                    field_inds.append(0)\n",
    "                elif type(nf) == list:\n",
    "                    note_inds += [note_ind] * len(nf)\n",
    "                    field_inds += list(range(len(nf)))\n",
    "            element_inds = range(len(note_inds))\n",
    "            self.f2i[field] = dict(zip(element_inds, zip(note_inds, field_inds)))\n",
    "    \n",
    "    def embed_database(self):\n",
    "        print(\"### Embedding DB ###\")\n",
    "        self.index = dict()\n",
    "        for field in SEARCH_FIELDS:\n",
    "            embeddings = []\n",
    "            emb_field = f\"{field}_emb\"\n",
    "            for note in self.db:\n",
    "                if emb_field in note:\n",
    "                    emb = note[emb_field]\n",
    "                else:\n",
    "                    nf = note[field]\n",
    "                    if type(nf) == str:\n",
    "                        emb = self.embed([nf])\n",
    "                    elif type(nf) == list:\n",
    "                        emb = self.embed(nf)\n",
    "\n",
    "                    note[emb_field] = emb\n",
    "                embeddings += emb \n",
    "            if not embeddings:\n",
    "                continue\n",
    "            \n",
    "            index = faiss.IndexFlatL2(self.model.config.hidden_size)\n",
    "            index.add(torch.vstack(embeddings))\n",
    "            self.index[field] = index\n",
    "        \n",
    "    def get_nearest(self, text, k=5, by_field='cleaned_note'):\n",
    "        index = self.index[by_field]\n",
    "\n",
    "        text_emb = self.embed([clean(text)])\n",
    "        D, I = index.search(torch.stack(text_emb), k)\n",
    "\n",
    "        nearest = self.get_notes_by_field(by_field, I[0])\n",
    "        for i, n in enumerate(nearest):\n",
    "            n['distance'] = D[0][i]\n",
    "        nearest = sorted(nearest, key=lambda n: n['distance'])\n",
    "        return nearest\n",
    "    \n",
    "    def get_notes_by_field(self, by_field, inds):\n",
    "        f2i = self.f2i[by_field]\n",
    "        out = []\n",
    "        for i in inds:\n",
    "            o = dict(**self.db[f2i[i][0]])\n",
    "            o['nearest_field'] = f2i[i][1]\n",
    "            out.append(o)\n",
    "        return out\n",
    "\n",
    "    def create_index(self, emb_matrix):\n",
    "        self.index = faiss.IndexFlatL2(self.model.config.hidden_size)\n",
    "        self.index.add(emb_matrix)\n",
    "  \n",
    "    def embed(self, texts, batch_size=32):\n",
    "        embeddings = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            text_batch = texts[i:i+batch_size]\n",
    "            tokenized = self.tokenizer.batch_encode_plus(text_batch, return_tensors='pt', padding='max_length', truncation=True)\n",
    "            for t in tokenized:\n",
    "                tokenized[t] = tokenized[t].to(self.device)\n",
    "            with torch.no_grad():\n",
    "                encoded = self.model(**tokenized)\n",
    "            for bn, states in enumerate(encoded.last_hidden_state):\n",
    "                emb = states[tokenized['attention_mask'][bn] == 1].mean(dim=0).cpu().detach()\n",
    "                embeddings.append(emb)\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def init_model(self, model_name, device):\n",
    "        print(\"### Loading model ###\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.model.eval()\n",
    "        self.model.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def load_db(self, from_scratch=False):\n",
    "        db_path = os.path.join(self.save_path, 'note_db.npy')\n",
    "        if not os.path.exists(db_path) or from_scratch:\n",
    "            self.db = []\n",
    "        else:\n",
    "            self.db = np.load(db_path, allow_pickle=True)\n",
    "    \n",
    "    def save(self):\n",
    "        os.makedirs(self.save_path, exist_ok=True)\n",
    "        db_path = os.path.join(self.save_path, 'note_db.npy')\n",
    "        np.save(db_path, self.db)\n",
    "\n",
    "    def suggest_tags(self, text):\n",
    "        drop_tags = {'', 'voice'}\n",
    "        nearest = self.get_knn(text, 10)\n",
    "        all_tags = ', '.join(nearest.tags.dropna()).split(', ')\n",
    "        all_tags = list(filter(lambda x: x not in drop_tags, all_tags))\n",
    "        suggested_tags = [t[0] for t in Counter(all_tags).most_common(4)]\n",
    "        return suggested_tags\n",
    "    \n",
    "    def start_timer(self):\n",
    "        class RepeatTimer(Timer):\n",
    "            def run(self):\n",
    "                while not self.finished.wait(self.interval):\n",
    "                    self.function(*self.args, **self.kwargs)\n",
    "\n",
    "        self.timer = RepeatTimer(1800, self.parse_notes)\n",
    "        self.timer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded = parse_folder(\"/home/booydar/sync/obsidian-db\", len_thr=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Loading model ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/booydar/Desktop/projects/env_projects/lib/python3.11/site-packages/transformers/modeling_utils.py:446: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Parsing notes ###\n",
      "### Adding notes ###\n",
      "### Buliding index ###\n",
      "### Embedding DB ###\n"
     ]
    }
   ],
   "source": [
    "tm = NoteManager(db_path=\"/home/booydar/sync/obsidian-db-test\",\n",
    "                    device='cpu',\n",
    "                    save_path=\"./saved_thoughts\",\n",
    "                    batch_size=32,\n",
    "                    # from_scratch=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Actually many of retrieval methods use question or query in each segment. This requires processing segments separately and this might be the point where recurrence is stronger, along reasoning over long contexts.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest[1]['paragraphs'][nearest[1]['nearest_field']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlimiformer seminar notes Retrieval does not necessarily VERY  reflect what a model needs to complete the task. \n",
      "!\n",
      "Unlimiformer seminar notes Actually many of retrieval methods use question or query in each segment. This requires processing segments separately and this might be the point where recurrence is stronger, along reasoning over long contexts.\n",
      "workshop on ML&bioinf Пример\n",
      "процесс сплайсинга\n",
      "Кодирующие участки записаны не подряд, между ними некодирующая последовательность. От него зависит, получится ли петелечка при сплайсинге)\n",
      "Простого ответа на то, какая должна быть последовательность, нет, только частично.\n",
      "Unlimiformer seminar notes Another interesting thing is how robust are retrieval methods to changes in the datastore. It affects how well it holds up over time and whether the whole system needs constant re-training.\n",
      "Unlimiformer seminar notes The long input is encoded in chunks and stored in a datastore. 6000 tokens -> 6000 embeddings. Then the retrieval happens on embedding level. During cross attention decoder attends to a part of this datastore that is retrieved by kNN search. \n",
      "Actually falls into the family of .\n",
      "To get the best contextualized embeddings for all tokens it is better to use overlapping chunks (middle half of the window is a nice balance): \n",
      "!\n",
      "But then positional embeddings during encoding look strange and we need to rely on decoder positional embeddings: !\n",
      "Another way of recording position is linear interpolating between 1, 2 and 3 on this img.\n"
     ]
    }
   ],
   "source": [
    "nearest = tm.get_nearest('Retrieval does not necessarily reflect what a model needs to complete the task. ', by_field='paragraphs')\n",
    "for n in nearest:\n",
    "    print(n['name'], n['paragraphs'][n['nearest_field']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "def llm(query):\n",
    "    response = ollama.chat(model='llama3',\n",
    "                            messages=[{'role': 'user', \n",
    "                                        'content': query}])\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''08-09-22 11:08\n",
    "#nlp #science \n",
    "\n",
    "---\n",
    "## A Mathematical Framework for Transformer Circuits\n",
    "[thread](https://transformer-circuits.pub/2021/framework/index.html#notation)\n",
    "[YT playlist](https://www.youtube.com/playlist?list=PLoyGOS2WIonajhAVqKUgEMNmeq3nEeM51)\n",
    "\n",
    "An attempt to interpret transformer as a combination of basic mathematical operations. In this paper only 0-2 layer **attention-only** (no MLP) transformers are studied, larger models are leaved for future work.\n",
    "\n",
    "**Simplifications**\n",
    "- MLP are hard to understand, so authors leave them out for elegance and simplicity.\n",
    "- No biases\n",
    "- No layer-norm\n",
    "- decoder-only\n",
    "\n",
    "### Summary of results\n",
    "\n",
    "-   Zero layer transformers model bigram statistics. The bigram table can be accessed directly from the weights.\n",
    "-   One layer attention-only transformers are an ensemble of bigram and “skip-trigram” The bigram and skip-trigram tables can be accessed directly from the weights.\n",
    "-   Two layer attention-only transformers can implement much more complex algorithms using compositions of attention heads (also be detected directly from the weights).\n",
    "-   One layer and two layer attention-only transformers use very different algorithms to perform in-context learning.\n",
    "\n",
    "![[Pasted image 20220908112200.png]]\n",
    "\n",
    "### Key takeaways\n",
    "- Attention head is an individual operation outputting a result into a residual system.\n",
    "- Attention is a sum of interpretable end-to-end functions\n",
    "- QK and OV are largely independent\n",
    "- q,k,v are intermediate results of multiplying low-rank Wq^TWk, WoWv\n",
    "- Composition of heads greatly increases the expressivity\n",
    "- token embedding, attention heads, MLP layers, and unembedding communicate with each other by reading and writing to different subspaces of the residual system **(?)**\n",
    "\n",
    "# Paradigm\n",
    "\n",
    "**Virtual weights**\n",
    "Authors separate residual connection to a so-called **stream**, that serves as a communication highway for layers. It can be thought of as virtual weights that link any pair of layers. Information flows in this stream until specifically removed with an element. The bandwith of the stream is relatively low in comparison to the number of preceding neurons => hiddens are challenging to interpret, easier to find out what a single head does.\n",
    "\n",
    "Each element (head) computes its own projection and adds it to the stream with own weight. Attention heads have low-dim projections (~64).\n",
    "\n",
    "![[Pasted image 20220908112455.png]]\n",
    "\n",
    "Some heads perform kind of **memory management** by writing out the negative version of some previously made changes.\n",
    "\n",
    "![[Pasted image 20220908113642.png]]\n",
    "\n",
    "It's important to think of attention heads as independent and additive elements that operate in parallel and add their output into the residual stream.\n",
    "\n",
    "The fundamental action of attention heads is moving information. They gather information from stream tokens and rewrite it into another stream token. Read and Write tokens here are completely sepate from each other! So are operations performing them\n",
    "\n",
    "### Observations\n",
    "- Attention heads move informations between tokens\n",
    "- Attention head is applying 2 linear operations: \n",
    "\t- A=SM(qT\\*k) - (non-linear one), governs information flow\n",
    "\t- WoWv - (linear one), which onformation is read and how to pass to destination\n",
    "\t- these operations act on different subspaces and act differently\n",
    "- Wq & Wk, Wo & Wv always operate together => may be substituted by low-rank matrices Wov, Wqk\n",
    "- q, k, v  are superficial, not really something crucial\n",
    "- ![[Pasted image 20220912115534.png]]\n",
    "\n",
    "\n",
    "## 0- and 1-layer Transformer\n",
    "**0 - layer** just counts bi-gram statistics\n",
    "**1 - layer**:\n",
    "\n",
    "![[Pasted image 20220912115742.png]]\n",
    "\n",
    "Rewrite using weight matrices and expand product: \n",
    "![[Pasted image 20220912130643.png]]\n",
    "First term does not move informations, just updates bigram statistics\n",
    "Second one links outputs and logits (kind of akin to [[gradient-based attention]] idea)\n",
    "\n",
    "### Split second term into circuits\n",
    "![[Pasted image 20220912133427.png]]\n",
    "\n",
    "So we've got 2 independent patterns that have different purposes. It allows us e.g. to first compute all attentions, freeze them and then produce output values for all tokens. This way logits are a **linear function** of input tokens!\n",
    "\n",
    "So we can just deal with matrices like *source*, *destination* -> *out*\n",
    "\n",
    "**Problems**:\n",
    "- large matrices for decent vocabs\n",
    "- qk weights can have different scale across heads\n",
    "- correlated variables\n",
    "\n",
    "**Positives**\n",
    "We can [explore](https://transformer-circuits.pub/2021/framework/head_dump/small_a.html) influence of bi-grams on output token probs by looking at maps.\n",
    "\n",
    "**Occurring patterns**\n",
    "- enormous fraction of attention capacity is copying ![[Pasted image 20220912134947.png]]\n",
    "- In-context learning patterns ![[Pasted image 20220912135230.png]]\n",
    "- Common phrases and constructions (e.g. `keep … [in → mind / at → bay / under → wraps]`, `difficult … not → impossible`)\n",
    "- Python patterns:\n",
    "\t- Predicting that the python keywords `else`, `elif` and `except` are more likely after an indentation is reduced using skip-trigrams of the form: `\\n\\t\\t\\t … \\n\\t\\t → else/elif/except` where the first part is indented N times, and the second part N-1, for various values of N, and where the whitespace can be tabs or spaces.\n",
    "\t- Predicting that `open()` will have a file mode string argument: `open … \",\" → [rb / wb / r / w]` (for example `open(\"abc.txt\",\"r\")`)\n",
    "\t- The first argument to a function is often `self`: `def … ( → self` (for example `def method_name(self):`)\n",
    "- **(!)** most trigrams relate to tokenization specifics\n",
    "- **(!)** many are hard to interpret without specific knowledge\n",
    "- **(!)** OV and QK matrices (50k x 50k) have extremely low rank (64, 128)\n",
    "\n",
    "### How common is copy behaviour?\n",
    "Copy is generally mapping a word to itself in a different context\n",
    "**Approach**: compare eigenvectors of OV matrices to the (1, 0) vector to find copying heads.\n",
    "\n",
    "![[Pasted image 20220912140252.png]]\n",
    "\n",
    "It appears that 10 of 12 heads are significantly copying! Well, on average. such eigenvalues are not rigorous proof.\n",
    "\n",
    "\n",
    "## Two-layer Transformers\n",
    "### Induction heads\n",
    "### More circuits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "[[00 NLP]]\n",
    "\n",
    "---'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_get_thoughts(text):\n",
    "    # prompt = '''Find 1-3 main ideas from the following text, formulate them very concisely. Text: {} Output !!ONLY!! 1-3 sentences: concise main ideas, separated by newline. '''\n",
    "    prompt = '''Summarize the following text in 2-3 sentences, formulate it very concisely. Text: {} Output only the concise summary, 2-3 sentences.'''\n",
    "    query = prompt.format(text)\n",
    "    ans = llm(query)\n",
    "    if '\\n' in ans: \n",
    "        ans = ans.split('\\n')[-1]\n",
    "    thoughts = ans.split('.')\n",
    "    thoughts = list(filter(len, thoughts))\n",
    "    return thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "thoughts = llm_get_thoughts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The paper presents a mathematical framework for understanding transformer circuits as combinations of basic mathematical operations',\n",
       " ' Specifically, it studies attention-only transformers with 0-2 layers and shows that these models can implement bigram statistics, skip-trigrams, and more complex algorithms using compositions of attention heads',\n",
       " ' The framework also reveals that attention heads move information between tokens and can be viewed as independent, additive elements operating in parallel']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = llm(\"Hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.chat(model='llama3', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Hello!',\n",
    "    },\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_models = ['llama3', 'llava']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/booydar/mpv-shot0001.jpg\"\n",
    "with open(file_path, 'rb') as f:\n",
    "    img = f.read()\n",
    "img_enc = base64.b64encode(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'ollama' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'ollama' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "ollama.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "response = ollama.chat(model='llava', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Whats on the image?',\n",
    "        'images': [img_enc]\n",
    "    },\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llava',\n",
       " 'created_at': '2024-04-25T16:50:32.524342442Z',\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': ' The image shows a landscape with rocks and vegetation in the foreground. In the background, there appears to be a river or body of water running through a valley or canyon. The terrain is rugged with varying elevations, suggesting it might be part of a mountainous region.\\n\\nOn the right side of the image, there\\'s an overlay of text and numerical data that seems to be related to a GPS or geographic tracking system. It includes information such as \"F2.8 5041,\" which likely refers to the camera settings and GPS coordinates, along with \"1/32s ISO: 640,\" which indicates exposure settings of the camera. The text also includes numbers like 2569, 5041, 4.73, 859, 1234, 0.83m, 200.00m/s, and 13.91, which might be additional data related to the GPS system or the image\\'s metadata.\\n\\nThe specific details about what exactly is being measured or recorded with this equipment are not clear from the image alone. '},\n",
       " 'done': True,\n",
       " 'total_duration': 3302513924,\n",
       " 'load_duration': 16488920,\n",
       " 'prompt_eval_count': 1,\n",
       " 'prompt_eval_duration': 580242000,\n",
       " 'eval_count': 248,\n",
       " 'eval_duration': 2462359000}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': \"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Loading existing model ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/booydar/Desktop/_projects/tg_notebot/env_neural/lib/python3.9/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/booydar/Desktop/_projects/tg_notebot/env_neural/lib/python3.9/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Parsing notes ###\n",
      "### Finished parsing ###\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/home/booydar/Desktop/_projects/tg_notebot/data/thoughts_cache\"\n",
    "note_db_path = \"/home/booydar/Sync/obsidian-db\"\n",
    "model_name = \"intfloat/multilingual-e5-large\"\n",
    "tm = ThoughtManager(note_db_path, \n",
    "                    model_name=model_name, \n",
    "                    save_path=save_path, \n",
    "                    device='cuda',\n",
    "                    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "thoughts = tm.note_db.thoughts.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = tm.note_db.cleaned_note.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Summarize the context in one short sentence.\\nContext: {}'''\n",
    "\n",
    "def summarize(text, prompt=prompt):\n",
    "    query = prompt.format(text)\n",
    "    return llm(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-11-30 01-48-47\\n\\n \\nКлассно было в универе не париться о том, что поправишься, о том что будешь тупой с утра. Просто бухаешь а потом идёшь на пары.\\n\\n '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A student is expressing frustration that they didn't bother to review their notes the night before and are now having to go to class without being prepared.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = '''Summarize the context in one short sentence.\\nContext: {}'''\n",
    "summarize(notes[0], prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-12-23 13-17-12\\n\\n \\nзабавно, что работу с обученными языковыми моделями можно сравнить с упрощением, потому что у самой модели нет никакой цели или глобального критерия правильности, кроме лоса, но вас не может нам помочь для решения задачи, на которую модель не была обучена.. это превращает inference или 0-shot модели в некоторое подобие укрощения или родео, где с помощью заправок и уговоров. Мы пытаемся заставить модели сделать то, что нам нужно.\\n\\n '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note = notes[10]\n",
    "note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'language, models, simplification, inference, task'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = '''Context: {}\\n Get 1-5 keywords for the context. Output ONLY keywords, split by a comma. Do NOT output anything else.'''\n",
    "llm(prompt.format(note))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [llm(prompt.format(note)) for note in notes[:30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "university, morning, classes, studying, habits 2022-11-30 01-48-47\n",
      "\n",
      " \n",
      "Классно было в универе не париться о том, что поправишься, о том что будешь тупой с утра. Просто бухаешь а потом идёшь на пары.\n",
      "\n",
      " \n",
      "photography, timeline, classification, images, sorting 2022-12-24 11-16-56\n",
      "\n",
      " \n",
      "Сайт с фотографиями, которые расположены в виде ленты. Сначала самая последняя потом по возрастанию возраста плюс, когда открываешь одну отдельную фотографию. Только ней подбираются наиболее похожи похожи стреляется базам случаев по среднему вектору, который получен с помощью обычного картона. Что-то типа разрезанная взять, а классификационная, чтобы получить распределение классов как бы.\n",
      "\n",
      " \n",
      "death, life, fear, suffering, happiness 2023-06-16 18-28-26\n",
      "\n",
      " \n",
      "Человек смерти боится, потому что жизнь любит вот как я понимаю. Итак, природа велела. Но это подло и тут весь обман жизнь есть боль жизни. Страх и человек несчастен. Теперь всё боль и страх. Теперь человек жизнь любит, потому что боль и страх любит и так сделали жизнь теперь даётся за более страх. И тут весь обман теперь человек ещё не тот человек будет новый Человек счастливый и гордый. Кому будет всё равно жить или не жить. Тот будет новый человек. Кто победит боль и страх тот сам Бог будет. \n",
      "\n",
      " \n",
      "psychological, armor, memory, faith, belief 2023-11-11 21-15-43\n",
      "\n",
      " \n",
      "помнить о доспехах, когда носишь психологический доспехи? Будь-то одежда маска верования убеждения и так далее села доспехов проявляется только когда о них помнишь. Если от этих доспехов забываешь, то они остаются лишь бессмысленной тряпкой и не работают. Поэтому для психологических доспехах необходимо они вспомнить. \n",
      "\n",
      " \n",
      "consciousness, clarity, understanding, reality, perception 2023-06-10 00-17-48\n",
      "\n",
      " \n",
      "Ну где же это ясность сознания, которая сопровождала меня ключевые моменты жизни, такие как Евпатория больше даже и не знаю, какие моменты были ключевыми. Пожалуй Евпатория соседа мехмате моменты стояния в курилке может быть поездки с одноклассниками, не встречи с универсальными друзьями. В такие моменты испытываешь какую-то ясность сознания и эту ясность так сложно иногда создать. Эта ясность мышления похоже на то, о чём говорил Йошуа Бенжио в своих высказываниях об его отношений с наукой периоды отчётливый ясностью сменяются периодами полного непонимания и дереализации науке либо жизни. Ответы на одни и те же вопросы могут казаться настолько очевидными в один момент, а в другой момент быть совершенно неразрешимыми, как же так, неужели действительно меняется объективная реальность или только субъективное восприятие. \n",
      "\n",
      " \n",
      "Planning, LLMs, Reasoning, Memory, Transformers 2023-11-01 12-32-21\n",
      "\n",
      " \n",
      "MB: planning is pretty bad for LLMs\n",
      "\n",
      "(https://cacm.acm.org/blogs/blog-cacm/276268-can-llms-really-reason-and-plan/fulltext?s=09)\n",
      "\n",
      "(https://arxiv.org/abs/2302.06706)\n",
      "\n",
      "What planning community did is rename the activities in Blocksworld. This very much affected the quality of LLM. Random names are even worse. It means  that LLMs learn a statistical model (world model) during pretraining. It we suppose that it has a model of the world, it is needed to plan a sequence of actions. These results show that maybe its not the case or LLM patterns are different from human ones. \n",
      "\n",
      "So maybe what LLM does is retrieve similar patterns from pre-training instead generalizing by learning rules. In order to do reasoning we need to shift pattern to pattern. \n",
      "\n",
      "This means that we can invent some architecture that is better with abstractions. It can result in a giant leap in capabilities. Actually the original memory transformer had this in mind when provided memory storage. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "logic, abstraction, consciousness, RLHF, cognition 2024-03-01 12-35-37\n",
      "\n",
      " \n",
      "необходимо выходить за пределы логики, общей и личной. за логикой в пространстве разума можно строить интуиции через совпадение смысла из разных областей сознания. не обязательно приземляясь эти смыслы в осознаваемым логику, главное - строить устойчивые комбинации которые сохраняются,  инварианты относительно преобразований между областями мышления. для этого нужна память как пространство, где возникают объекты, как-то следующие из цепочек физических атомов мышления. такие объекты по видимому можно сохранять в виде объемных текстов, которые занимаются без особого мышления, просто как поток сознания. \n",
      "\n",
      "часто построение таких абстракций - машин, перерабатывающих мышление, напоминает языковые модели, пробегающие по текстам и собирающие смыслы в хранилище. вот только там смыслы имеют довольно после назначение - предсказать будущее. возможно, более правильный вектор - как раз сознание абстракций, устойчивых к перемене входного текста.\n",
      "\n",
      "не по какому поводу собираются абстракции у реального человека? по совокупности биологических причин и ожидания будущих и прошлых вознаграждений от системы наград. \n",
      "\n",
      " системы напомнишь rlhf, но должна обучаться целям суммой модели, а не сомневаться из человеческих предпочтений. она оценивает генерации и состояния, возникающие в абстрактной рабочей памяти \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "risk, trust, self, calculation, adrenalin 2024-02-19 23-24-32\n",
      "\n",
      " \n",
      "нужно больше рисковать. \n",
      "риск это момент бессилия, непросчитанных обстоятельств. в этот момент нужно довериться себе, поверить, что ты можешь справиться со всеми проблемами по мере поступления. отсутствие риска может быть вызвано привычкой к глубокому расчету, оно делает вдумчивым и трусливым. справиться можно силой воли либо через адреналиновые занятия \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "knowledge, interface, telegram, bot, hashtags 2022-11-19 21-46-17\n",
      "\n",
      " \n",
      "Идея сделать взаимодействие с базы знаний с интерфейсом через телеграм бота, например, найти все заметки по данному Хэштегу или идея найти все заметки похожую на данную.\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Ideas, Money, Power, Honor, Worth 2023-01-16 11-00-05\n",
      "\n",
      " \n",
      "Интересная идея состоит в том, что вместо денег либо материальных ценностей, которые можно давать человеку за труд, существует другая субстанция, которая также может его вознаграждать.\n",
      "\n",
      "Такой субстанцей является почёт либо власть. почёт или власть не всегда связаны с деньгами напрямую, подтверждением тому могут служить люди обладающие почётным званием но маленьким состоянием.\n",
      "\n",
      " \n",
      "языковые, модели, упрощение, inference, обучены 2022-12-23 13-17-12\n",
      "\n",
      " \n",
      "забавно, что работу с обученными языковыми моделями можно сравнить с упрощением, потому что у самой модели нет никакой цели или глобального критерия правильности, кроме лоса, но вас не может нам помочь для решения задачи, на которую модель не была обучена.. это превращает inference или 0-shot модели в некоторое подобие укрощения или родео, где с помощью заправок и уговоров. Мы пытаемся заставить модели сделать то, что нам нужно.\n",
      "\n",
      " \n",
      "innovation, progress, winner, mentality, science, intelligence, talent, motivation, PhD 2023-07-27 11-57-32\n",
      "\n",
      " \n",
      "Pavel Osinenko:\n",
      "You will never make something absolutely innovative, that's impossible, the humanity makes progress with small steps. A winner is someone who is mentally stable and patient enough not to give up and work hard \n",
      "\n",
      "Georgy Malaniya:\n",
      "Тезис 1: я никогда не пойду на галеру\n",
      "Я буду ебашить за стипендию до тех пор пока не дожму то, что будет давать возможность жить тем, что дает мне сил жить\n",
      "\n",
      "Тезис 2: холодный или горячий старт ничего не решает\n",
      "В долгосроке будет какая то дельта возможно, но она будет со временем очень мала. Все решает исключительно труд, это я для себя точно уяснил\n",
      "\n",
      "Нет смысла думать о достижениях на школьных олимпиадах, студенческих паперах \n",
      "Самый настоящий спорт начинается после пхд\n",
      "\n",
      "Когда у тебя нет облиг, когда развязаны руки, есть степень и бэкап в виде галеры на которую можно уйти за 300к наносек\n",
      "\n",
      "\n",
      "Вообще один из самых больших приколов науки это что можно стать ебать рок звездой на самом деле, если ты +- обладаешь интеллектом и талантом ебашить в нужном направлении. \n",
      "в последнее время часто стал встречать на конфах и просто в работах челов, которые ну просто охуеть) почитал вот диссер ilya sutskever, (который кста chatgpt лидил и в cv тоже много чего сделал) и у него в год по 4-5 статей на топовых конференциях и так 5 лет PhD) ну это как пример просто. \n",
      "У тебя тоже есть какое-то внутреннее охуевание от таких челов? Иногда такое мотивирует а иногда наоборот понимаешь, что ты как бы на более холодном старте что ли и вообще мб тогда уйти умирать в условный сбер на лидовскую зп и не ебать мозг?) Чо думаешь по этому поводу, бывает ли,как справляешься\n",
      "\n",
      " \n",
      "data, memory, recurrence, Revell, generation 2023-06-19 20-43-25\n",
      "\n",
      " \n",
      "По сути, задачи поиска похожие заметки или нескольких похожих заметок в базе данных и дальнейшей генерация ответа или продолжение текущее заметки на основании подобранного очень похоже на модели Revell модели. Каким-то образом нужно понять, как в эту парадигму устроить идею рекуррентный памяти, в чём же смысл рекуррентно сти в чём её преимущества перед римом и как их совместить. \n",
      "\n",
      " \n",
      "ideas, memory, communication, travel, simplicity 2023-07-17 12-55-04\n",
      "\n",
      " \n",
      "Мысли Шри Ланка\n",
      "\n",
      "- пространство человеческих идей непрерывно и задаётся кучей параметров, любые дискретные явления в нем вроде пересечения и комбинации идей - просто явные области непрерывных эффектов\n",
      "- ощущения с нескольких моментов складываются в одно осознанное восприятие.  их связывает память - способ передачи информации из прошлых в текущее восприятие. информация может передаваться на разных уровнях и областях восприятия - запахи, смутное ощущение, сочетание букв, паттерны, цвет, ... также информация из памяти может быть частью текущего восприятия.\n",
      "- поставлена задача перестать испытывать неловкость при ненапряжном общении с незнакомцами. в частности принять несогласия и недопонимания, это норма.\n",
      "+ общение с малым кругом людей и постоянное следование желаемому приводит к внутренней капризности, сложности разрешать, отпускать нежелаемое\n",
      "- новозеландцы - летчик с красными глазами и девушка, познакомившиеся на Бали \n",
      "- каноничный австралиец - акцент, mate, got sooo drunk last night, телосложение, серф\n",
      "- когда едешь в отпуск, в какой-то момент переступаешь материалистический барьер и отпускаешь расходы. нужно как можно быстрее это делать, чтобы переходить полностью в состояние отпуска\n",
      "- память это временной ряд со своими зависимостями, сезонностями, трендами. есть шумные зависимости, приближаемые законами связи с прошлым. моделировать связь между прошлым и будущим как временной ряд?\n",
      "- Фейнман - няшка (в научном смысле)\n",
      "- в каждый момент времени ты как агент представляешь себя в разных состояниях и составляешь возможные действия\n",
      "- кальянщик на самом деле выполняет работу фильтра от самого тяжёлого в калике\n",
      "- почему-то оно не отпускает. кажется, что если развяжешь все узелки, то должно отпустить. может, не все узелки развязаны? надо копнуть глубже, в детство или нетривиальное. например, в совсем базовые эмоции посмотреть, их причины.\n",
      "- вот некоторым вещам просто не суждено случиться. более того, они замечательны именно этим. например, дружественные отношения с кем-то из туризма, близкое к дружескому общению с незнакомцами\n",
      "- какая-то глубокая неловкость из-за неумелого общения что ли, что в развлекательном, что в научном плане. нужна видимо какая-то простота в подборе и отпускании людей\n",
      "- ещё одна причина - накатывающее ощущение своих недостатков. это только усугубляет воронку\n",
      "- возможно, все чувства воронки это на самом деле одно, которое никак не даётся сознанию. вот ближе всего - чувство страха потери\n",
      "- может ли мозг ходить по мысленным тропам, не появившимся до этого в подсознании? постоянно ли подсознание работает? отдельная ли это часть мозга или это слишком сильное название \n",
      "\n",
      " \n",
      "marketing, information, technology, development, humanity 2023-09-15 18-26-26\n",
      "\n",
      " \n",
      "по маркетингу фото для заметок развитие человечества очень сильно зависит от передачи информации из поколения в поколение, а также от способов сохранения и организации этой информации. По большей части люди стали жить намного лучше. Когда стали появляться источники и средства хранения информации, которые позволили сделать технологический прорыв. Теперь можно посмотреть на средства хранения информации сейчас и их развития и сделать из этого вывод, что они несовершенны и способом качества технологического прорыва. Будет изобретение нового способа хранения передачи организации и анализа информации. \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "children, mother, door, car, open 2023-06-16 18-36-37\n",
      "\n",
      " \n",
      "прохожу мимо женщины с детьми, которые садятся в машину. Дети дёргают ручку двери. Дверь не открывается. Подходят мама говорит, да она открыта. Потом открывает машину, и дети открывают двери так вот вопрос, какого х. \n",
      "\n",
      " \n",
      "systems, cooperation, project, motivation, synergy 2023-08-20 00-18-19\n",
      "\n",
      " \n",
      "системы, где общая цель выгодна каждому из элементов работают лучше всего. Примером такой системы может быть проект, в котором каждый из участников получает выгоду от сотрудничества свою либо сюжет фильма, где мотивация каждого из персонажей способствует развитию сюжета. \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "осознанность, философия, буддизм, настройка, выбор 2022-11-27 18-14-28\n",
      "\n",
      " \n",
      "майндсет роста напрямую связан с идеей осознанностью философии осознанности и буддизма в сети просто целью является настройка себя на увеличение выброса от сложности выполняемого действия это очень похоже на идею того чтобы жить настоящим то есть проживать каждый момент чувствовать его максимально полно потому что чувствовать и есть увеличить выработку дофамина от каждого рецептора\n",
      "\n",
      " \n",
      "control, attention, productivity, marketing, media 2023-08-10 11-27-40\n",
      "\n",
      " \n",
      "Итак, идея для инструмента контроля внимание контроль внимания. Это супер важно, потому что это самый важный ресурс, который есть у тебя для продуктивности за ним охотятся все, кому ты нужен как потребитель, то есть реклама продуктов, услуг и так далее На это направленные силы маркетологов. Идея состоит в том, чтобы получать только необходимые полезные фичи от продуктов, не попадая под отрицательное влияние. Для этого необходимо создать собственную ленту новостей во-первых и во-вторых перейди, например, чтобы использовать социальные сети и информационные источники более эффективно. Поэтому необходимо добавить ещё и полезные привычки, чтобы сформировать способ взаимодействия с медиа, который будет выгоден для тебя, а не для кого-то ещё. \n",
      "\n",
      " \n",
      "bot, skill, evening, article, Wikipedia, education, science 2022-11-22 22-09-47\n",
      "\n",
      " \n",
      "Добавить для бота навык каждый вечер отправлять, что-то полезное, например, статью из Википедии или научную статью для постоянного образования.\n",
      "\n",
      " \n",
      "friends, motivate, know, spirit, own 2023-05-29 21-27-23\n",
      "\n",
      " \n",
      "Не обязательно познавать мир с друзьями, которые максимально близкими к тебе по духу. Достаточно просто найти тех, кто мотивирует тебя, познавать и делать собственные выводы. \n",
      "\n",
      " \n",
      "Neural network, Sigmoid function, Activation function, Full connection, Telegram 2023-02-20 18-55-56\n",
      "\n",
      " \n",
      "для лекции рассказать про нейронную сеть, полносвязную с сигмоидой как функцию активации. сигмоида-это сжимающая отображение и у любого нажимающего отображения. Есть неподвижная точка На практике получается, что если сигмоиду применить много раз, то она как-раз и сжимает это отображение в свою неподвижную точку. Пример есть в телеграме.\n",
      "\n",
      " \n",
      "family, value, optimization, economics, society 2023-12-15 12-27-41\n",
      "\n",
      " \n",
      "Семья и экономика интересно посмотреть на семью с точки зрения той ценности, которую она пытается оптимизировать, то есть семейного излишка. Это такой набор ценности, которые аккумулируются в семье и которая не аккумулировать бы в случае её отсутствия с развитием общество накапливать ценность и существовать отдельно становилось всё проще, что приводило к большей атомизации семьи, То есть семья становятся более атомарной и необязательно иметь хозяйства из большого количества людей, чтобы себя прокормить, задумываться. Теперь стоит насколько семья и конкретные люди помогают увеличивать стоимость семей. Прибавят ли этой стоимости добавления нового человека в эту семью или наоборот убавить стоимость же. Это может выражаться не только в чём-то материальном, но и в благосостоянии в целом. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "train, Arab, lab, university, communication 2023-06-10 00-18-37\n",
      "\n",
      " \n",
      "сидел сегодня в электричке после пикника с лабораторией Ксюша и рами разговаривали на арабском раме или него это родной язык, а Ксюша учила его в университете. Я испытал какое-то поразительное чувство я сидел и смотрел на них с открытым ртом. Это было так странно и чудесно видеть эту коммуникацию ощущать, что происходит, что-то связывающие людей национальности разного происхождения не говорят на языке. Этот язык совершенно непонятен не могут быть законы, которые совершенно отличаются от языка, на котором ты говоришь. Может быть этот язык даже приводит тебя в разные места совершенно другие места, отличные от тех, которые тебе разрешен доступ. Эти истории прекрасно. \n",
      "\n",
      " \n",
      "machine learning, метрики, пространство, расстояние, свойста 2023-10-18 19-47-31\n",
      "\n",
      " \n",
      "Пространство и метрики в машинном обучении мне уже довольно давно захватывает Идея о том, что классическое метрическое пространство, в частности, Евклидова, которые мы используем для машинного обучения, может быть не идеально в каких--то ситуациях. Вот, например, на воркшопе Huawei мой институтский преподаватель Иванов выступал с докладом о том, что можно использовать необычное расстояние, чтобы лучше разделять карте. Мне кажется, это довольно банально примером, но в целом хотелось бы подумать над свойствами расстояние в целом и применимости этих свойств к пространством скрытых представлений в машинном обучении. Это может помочь более правильно находиться отношения между объектами в этих пространствах, если мы знаем какие-то свойства. \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "life, calm, basketball, relaxed, moment 2023-03-27 11-27-31\n",
      "\n",
      " \n",
      "быть спокойным и размеренным в любой момент. как в баскетболе, ты ведёшь жизнь а не наоборот \n",
      "\n",
      " \n",
      "Artificial Intelligence, Access, Speed, Applications, Knowledge Base 2023-03-19 09-53-39\n",
      "\n",
      " \n",
      "Надо сделать прикладное искусственный интеллект максимально быстрым для доступа, чтобы можно было вот таким же образом, как я сейчас говорю получать к нему доступ и менять его режимы между поиском по сети генеративным ответом и ответом на основание базы знаний. Собственный и у этой системы более ограничены множество область применимости, поэтому поэтому к ней и требования меньше, чем к общему искусственному интеллекту.\n",
      "\n",
      " \n",
      "ceal, purpose, consciousness, outside, movement 2023-07-20 11-07-01\n",
      "\n",
      " \n",
      "Когда мы говорим о цели, почему-то подразумевается о том, что она находится в из вне человеческого сознания, хотя вроде бы очевидно, что наоборот цель по определению — это то, куда движется человеческое сознание?\n",
      "\n",
      " \n",
      "Money, happiness, freedom, self-discovery, purpose 2023-09-17 01-29-54\n",
      "\n",
      " \n",
      "Ролики пьюдипая это, по сути, очень похоже на то, чем бы ты занимался Будете тебя бесконечное количество денег и просто возможно сделать всё чего ты хочешь. Это очень хорошо показывает тебе чего ты? Почему тебя реально тянет? Я же интересно смотреть на человека, который реально не подвластен стремлению работать у него есть куча потенциальные возможности. Единственная твоя задача жизнь в соответствии с принципами, которые у тебя есть и совместить желание тебя и твоих близких людей. Это так странно и одновременно прикольно, и пожалуй позволяет открыть себя максимально как человека. \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "finance, idea, entrepreneurship, coding, income 2023-04-22 20-55-52\n",
      "\n",
      " \n",
      "Нужно искать финансовую идеи очень близко к своей основной деятельности. В таком случае можно будет минимальными затратами получать дополнительный доход, то, что у кого-то заняло бы много времени на реализацию. У тебя может занять несколько вечеров кодинга. \n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for k, n in zip(keywords, notes):\n",
    "    print(k, n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_neural",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
