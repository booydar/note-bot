{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import json\n",
    "from threading import Timer\n",
    "from collections import Counter\n",
    "import torch\n",
    "import faiss                 \n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def clean(note):\n",
    "    # remove zero-links\n",
    "    note = re.sub(r'\\[.*\\]', '', note)\n",
    "    # remove tags and headers\n",
    "    note = re.sub(r'\\#.*\\n', '', note)\n",
    "    # remove lines\n",
    "    note = re.sub('---', ' ', note)\n",
    "    # remove **\n",
    "    note = re.sub('\\*', '', note)\n",
    "    \n",
    "    return note\n",
    "\n",
    "def clean_thought(thought):\n",
    "    thought = re.sub(r'\\(http\\S+', '<LINK>', thought)\n",
    "    thought = re.sub(r'http\\S+', '<LINK>', thought)\n",
    "\n",
    "    if thought[:2] == '- ':\n",
    "        thought = thought[2:]\n",
    "\n",
    "    if '<LINK>' in thought:\n",
    "        linkless = re.sub('<LINK>', '', thought)\n",
    "        linkless = re.sub('[^a-zA-Zа-яА-Я ]', '',  linkless)\n",
    "        linkless = linkless.strip()\n",
    "        if len(linkless.split(' ')) < 2:\n",
    "            return ''\n",
    "    \n",
    "    return thought.strip()\n",
    "\n",
    "\n",
    "def filter_thought(thought):\n",
    "    if not thought:\n",
    "        return False\n",
    "    \n",
    "    thought = str(thought)\n",
    "    letters_only = re.sub('[^a-zA-Zа-яА-Я]', '',  thought)\n",
    "    if len(letters_only) < 30:\n",
    "        return False\n",
    "    \n",
    "    words_only = re.sub('[^a-zA-Zа-яА-Я ]', '',  thought)\n",
    "    if len(words_only.split(' ')) < 10:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def find_tags(note):\n",
    "    tags = re.findall(\"\\B(\\#[a-zA-Z]+(\\n|\\ ))\", note)\n",
    "    tags = [t.split(s)[0][1:] for (t, s) in tags]\n",
    "    return tuple(tags)\n",
    "\n",
    "\n",
    "def parse_folder(db_path, len_thr=40):\n",
    "    path, folders, files = next(os.walk(db_path))\n",
    "\n",
    "    subfolder_dbs = []\n",
    "    if len(folders) > 0:\n",
    "        for f in folders:\n",
    "            folder_path = os.path.join(path, f)\n",
    "            folder_db = parse_folder(folder_path, len_thr)\n",
    "            subfolder_dbs.append(folder_db)\n",
    "\n",
    "    db = []\n",
    "    for fn in files:\n",
    "        if '.md' not in fn:\n",
    "            continue\n",
    "\n",
    "        filepath = os.path.join(path, fn)\n",
    "        with open(filepath, 'r') as f:\n",
    "            note = f.read()\n",
    "\n",
    "        if len(note) < len_thr:\n",
    "            continue\n",
    "        cleaned_note = clean(note)\n",
    "        tags = find_tags(note)\n",
    "        thoughts = get_thoughts(cleaned_note)\n",
    "        note_dict = {'name': fn.split('.md')[0], 'path':filepath, \n",
    "                     'note':note, 'cleaned_note': cleaned_note, \n",
    "                     'thoughts': thoughts, 'tags': tags}\n",
    "        db.append(note_dict)\n",
    "\n",
    "    db = db + subfolder_dbs\n",
    "    return db\n",
    "\n",
    "\n",
    "def get_thoughts(note):\n",
    "    thoughts = [t for thought in re.split('\\n|\\t', note) for t in nltk.sent_tokenize(thought)]\n",
    "    cleaned_thoughts = list(map(clean_thought, thoughts))\n",
    "    filtered_thoughts = list(filter(filter_thought, cleaned_thoughts))\n",
    "    return filtered_thoughts\n",
    "\n",
    "\n",
    "class NoteDatabase:\n",
    "    def __init__(self, db_path, \n",
    "                        model_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
    "                        device='cpu',\n",
    "                        save_path='../saved',\n",
    "                        batch_size=32):\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        self.db_path, self.save_path, self.batch_size = db_path, save_path, batch_size\n",
    "        self.init_model(model_name, device)\n",
    "        self.parse_notes()\n",
    "        self.start_timer()\n",
    "    \n",
    "    def parse_notes(self):\n",
    "        print(\"### Parsing notes ###\")\n",
    "        loaded = parse_folder(self.db_path, len_thr=40)\n",
    "\n",
    "        db_path = os.path.join(self.save_path, 'note_db.json')\n",
    "        if os.path.exists(db_path):\n",
    "            with open(db_path, 'r') as f:\n",
    "                loaded_db = json.load(f)\n",
    "            embeddings = np.load(os.path.join(self.save_path, 'embeddings.npy'))\n",
    "\n",
    "            set_notes = set(n['note'] for n in self.db)\n",
    "            new_notes = [n for n in loaded_db if n['note'] not in set_notes]\n",
    "            \n",
    "            # remove old notes that were changed\n",
    "            new_paths = set([n['path'] for n in new_notes])\n",
    "            changed_note_inds = {i for (i, n) in enumerate(self.db) if n['path'] in new_paths}\n",
    "            self.db = [n for i, n in enumerate(self.db) if i not in changed_note_inds]\n",
    "            self.embeddings = [n for i, n in enumerate(self.embeddings) if i not in changed_note_inds]\n",
    "\n",
    "\n",
    "            # self.db = [n for n in self.db if n['path'] not in new_paths] \n",
    "            # self.embeddings = [e for e in self.embeddings if n['path'] not in new_paths] # remove old notes that were changed\n",
    "            # unchanged_inds = [i for i, (old, new) in enumerate(zip(self.db, loaded_db)) if old['note'] == new['note']]\n",
    "            # self.db = []\n",
    "\n",
    "            # changed = []\n",
    "\n",
    "            # parsed_paths = set(parsed.path)\n",
    "            # loaded_paths = set(loaded.path)\n",
    "            \n",
    "            # drop deleted notes            \n",
    "            self.embeddings = embeddings[loaded.path.isin(parsed_paths)]\n",
    "            self.note_db = loaded[loaded.path.isin(parsed_paths)]\n",
    "\n",
    "            new_paths = parsed_paths.difference(loaded_paths)\n",
    "            if len(new_paths) > 0:\n",
    "                # add new notes\n",
    "                new_thoughts = parsed[~parsed.path.isin(loaded_paths)]\n",
    "                new_embeddings = self.embed(list(new_thoughts.thoughts.values), self.batch_size)\n",
    "\n",
    "                self.note_db = pd.concat((self.note_db, new_thoughts))\n",
    "                self.embeddings = np.concatenate((self.embeddings, new_embeddings), axis=0)\n",
    "        else:\n",
    "            self.note_db = loaded\n",
    "            self.embeddings = self.embed(loaded, self.batch_size)\n",
    "        \n",
    "        self.create_index(self.embeddings)\n",
    "        self.save()\n",
    "        print(\"### Finished parsing ###\")\n",
    "\n",
    "    def get_nearest(self, note, k):\n",
    "        thoughts = get_thoughts(clean(note))\n",
    "        nearest = [self.get_knn(t, k=k) for t in thoughts]\n",
    "        if len(nearest) > 0:\n",
    "            nearest = pd.concat(nearest)\n",
    "        else: \n",
    "            nearest = self.get_knn(clean(note), k=k)\n",
    "        return nearest.sort_values('distance')\n",
    "\n",
    "    def get_knn(self, thought, k=5):\n",
    "        text_embedding = self.embed([thought])\n",
    "\n",
    "        D, I = self.index.search(text_embedding, k)\n",
    "        nearest = self.note_db.iloc[I[0]].copy()\n",
    "        nearest['distance'] = D[0]\n",
    "        return nearest\n",
    "\n",
    "    def create_index(self, emb_matrix):\n",
    "        self.index = faiss.IndexFlatL2(self.model.config.hidden_size)\n",
    "        self.index.add(emb_matrix)\n",
    "  \n",
    "    def embed(self, texts, batch_size=32):\n",
    "        embeddings = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            text_batch = texts[i:i+batch_size]\n",
    "            tokenized = self.tokenizer.batch_encode_plus(text_batch, return_tensors='pt', padding='max_length', truncation=True)\n",
    "            for t in tokenized:\n",
    "                tokenized[t] = tokenized[t].to(self.device)\n",
    "            with torch.no_grad():\n",
    "                encoded = self.model(**tokenized)\n",
    "            for bn, states in enumerate(encoded.last_hidden_state):\n",
    "                emb = states[tokenized['attention_mask'][bn] == 1].mean(dim=0).cpu().detach()\n",
    "                embeddings.append(emb)\n",
    "\n",
    "        return torch.vstack(embeddings)\n",
    "\n",
    "    def init_model(self, model_name, device):\n",
    "        model_path = os.path.join(self.save_path, 'model.pth')\n",
    "        tokenizer_path = os.path.join(self.save_path, 'tokenizer.pth')\n",
    "        if os.path.exists(model_path):\n",
    "            print(\"### Loading existing model ###\")\n",
    "            self.tokenizer = torch.load(tokenizer_path)\n",
    "            self.model = torch.load(model_path)\n",
    "        else:\n",
    "            print(\"### Downloading model ###\")\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            self.model = AutoModel.from_pretrained(model_name)\n",
    "            torch.save(self.tokenizer, tokenizer_path)\n",
    "            torch.save(self.model, model_path)\n",
    "        self.model.eval()\n",
    "        self.model.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def suggest_tags(self, text):\n",
    "        drop_tags = {'', 'voice'}\n",
    "        nearest = self.get_knn(text, 10)\n",
    "        all_tags = ', '.join(nearest.tags.dropna()).split(', ')\n",
    "        all_tags = list(filter(lambda x: x not in drop_tags, all_tags))\n",
    "        suggested_tags = [t[0] for t in Counter(all_tags).most_common(4)]\n",
    "        return suggested_tags\n",
    "    \n",
    "    def save(self):\n",
    "        if not os.path.exists(self.save_path):\n",
    "            os.system(f'mkdir {self.save_path}')\n",
    "\n",
    "        self.note_db.to_csv(os.path.join(self.save_path, 'thoughts.csv'), sep=';', index=False)\n",
    "        np.save(os.path.join(self.save_path, 'embeddings.npy'), self.embeddings)\n",
    "    \n",
    "    def start_timer(self):\n",
    "        class RepeatTimer(Timer):\n",
    "            def run(self):\n",
    "                while not self.finished.wait(self.interval):\n",
    "                    self.function(*self.args, **self.kwargs)\n",
    "\n",
    "        self.timer = RepeatTimer(1800, self.parse_notes)\n",
    "        self.timer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Loading existing model ###\n",
      "### Parsing notes ###\n",
      "### Finished parsing ###\n"
     ]
    }
   ],
   "source": [
    "tm = ThoughtManager(db_path=\"/home/booydar/Sync/obsidian-db/\",\n",
    "                    device='cuda',\n",
    "                    save_path=\"./saved_thoughts\",\n",
    "                    batch_size=512\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-16 18-28-26\n",
      "\n",
      " \n",
      "Человек смерти боится, потому что жизнь любит вот как я понимаю. Итак, природа велела. Но это подло и тут весь обман жизнь есть боль жизни. Страх и человек несчастен. Теперь всё боль и страх. Теперь человек жизнь любит, потому что боль и страх любит и так сделали жизнь теперь даётся за более страх. И тут весь обман теперь человек ещё не тот человек будет новый Человек счастливый и гордый. Кому будет всё равно жить или не жить. Тот будет новый человек. Кто победит боль и страх тот сам Бог будет. \n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(tm.note_db.cleaned_note.values[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Loading existing model ###\n",
      "### Parsing notes ###\n",
      "### Finished parsing ###\n"
     ]
    }
   ],
   "source": [
    "tm1 = ThoughtManager(db_path=\"/home/booydar/Sync/obsidian-db/\",\n",
    "                    device='cuda',\n",
    "                    save_path=\"./saved_thoughts\",\n",
    "                    batch_size=512\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database:\n",
    "    def __init__(self, save_folder=\"./save\"):\n",
    "        self.save_folder = save_folder\n",
    "        self.db = []\n",
    "\n",
    "\n",
    "    def parse_folder(self, db_path, len_thr=40):\n",
    "        path, folders, files = next(os.walk(db_path))\n",
    "\n",
    "        subfolder_dbs = []\n",
    "        if len(folders) > 0:\n",
    "            for f in folders:\n",
    "                folder_path = os.path.join(path, f)\n",
    "                folder_db = parse_note_db(folder_path, len_thr)\n",
    "                subfolder_dbs.append(folder_db)\n",
    "\n",
    "        db = []\n",
    "        for fn in files:\n",
    "            if '.md' not in fn:\n",
    "                continue\n",
    "\n",
    "            filepath = os.path.join(path, fn)\n",
    "            with open(filepath, 'r') as f:\n",
    "                note = f.read()\n",
    "\n",
    "            if len(note) < len_thr:\n",
    "                continue\n",
    "            cleaned_note = clean(note)\n",
    "            tags = find_tags(note)\n",
    "            thoughts = get_thoughts(cleaned_note)\n",
    "            note_dict = {'name': fn.split('.md')[0], 'path':filepath, 'note':note, 'cleaned_note': cleaned_note, 'thoughts': thoughts, 'tags': tags}\n",
    "            db.append(note_dict)\n",
    "\n",
    "        db = db + subfolder_dbs\n",
    "        self.db = db\n",
    "        return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path=\"/home/booydar/Sync/obsidian-db/\"\n",
    "\n",
    "\n",
    "DB = Database(save_folder=\"./saved_thoughts/\")\n",
    "db = DB.parse_folder(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'RMT framework',\n",
       " 'path': '/home/booydar/Sync/obsidian-db/RMT framework.md',\n",
       " 'note': \"17-08-22 16:20\\n#rmt #nlp #science \\n\\n---\\n### A vision of RMT as more than just one model\\n\\n**Idea**: \\nwe've tried a lot of things with memory, but each one of them works in different situations. We can see RMT as a memory framework, where a user can experiment with flags based on his own task with his own models.\\n\\nTechnically, it means that all changes in RMT should be made in a clear way so that they don't interrupt with each other.\\n\\n---\\n[[00 RMT]] \\n\\n---\\n\",\n",
       " 'cleaned_note': \"17-08-22 16:20\\n\\n \\n\\nIdea: \\nwe've tried a lot of things with memory, but each one of them works in different situations. We can see RMT as a memory framework, where a user can experiment with flags based on his own task with his own models.\\n\\nTechnically, it means that all changes in RMT should be made in a clear way so that they don't interrupt with each other.\\n\\n \\n \\n\\n \\n\",\n",
       " 'thoughts': [\"we've tried a lot of things with memory, but each one of them works in different situations.\",\n",
       "  'We can see RMT as a memory framework, where a user can experiment with flags based on his own task with his own models.',\n",
       "  \"Technically, it means that all changes in RMT should be made in a clear way so that they don't interrupt with each other.\"],\n",
       " 'tags': ('rmt', 'nlp', 'science')}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Parsing notes ###\n"
     ]
    }
   ],
   "source": [
    "db[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo\n",
    "- implement version checking??\n",
    "- dont parse if notes are ok\n",
    "- free memory after embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "def llm(query):\n",
    "    response = ollama.chat(model='llama3', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': query,\n",
    "    },\n",
    "    ])\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = llm(\"Hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.chat(model='llama3', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Hello!',\n",
    "    },\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_models = ['llama3', 'llava']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/booydar/mpv-shot0001.jpg\"\n",
    "with open(file_path, 'rb') as f:\n",
    "    img = f.read()\n",
    "img_enc = base64.b64encode(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'ollama' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'ollama' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "ollama.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "response = ollama.chat(model='llava', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Whats on the image?',\n",
    "        'images': [img_enc]\n",
    "    },\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llava',\n",
       " 'created_at': '2024-04-25T16:50:32.524342442Z',\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': ' The image shows a landscape with rocks and vegetation in the foreground. In the background, there appears to be a river or body of water running through a valley or canyon. The terrain is rugged with varying elevations, suggesting it might be part of a mountainous region.\\n\\nOn the right side of the image, there\\'s an overlay of text and numerical data that seems to be related to a GPS or geographic tracking system. It includes information such as \"F2.8 5041,\" which likely refers to the camera settings and GPS coordinates, along with \"1/32s ISO: 640,\" which indicates exposure settings of the camera. The text also includes numbers like 2569, 5041, 4.73, 859, 1234, 0.83m, 200.00m/s, and 13.91, which might be additional data related to the GPS system or the image\\'s metadata.\\n\\nThe specific details about what exactly is being measured or recorded with this equipment are not clear from the image alone. '},\n",
       " 'done': True,\n",
       " 'total_duration': 3302513924,\n",
       " 'load_duration': 16488920,\n",
       " 'prompt_eval_count': 1,\n",
       " 'prompt_eval_duration': 580242000,\n",
       " 'eval_count': 248,\n",
       " 'eval_duration': 2462359000}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': \"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Loading existing model ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/booydar/Desktop/_projects/tg_notebot/env_neural/lib/python3.9/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/booydar/Desktop/_projects/tg_notebot/env_neural/lib/python3.9/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Parsing notes ###\n",
      "### Finished parsing ###\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/home/booydar/Desktop/_projects/tg_notebot/data/thoughts_cache\"\n",
    "note_db_path = \"/home/booydar/Sync/obsidian-db\"\n",
    "model_name = \"intfloat/multilingual-e5-large\"\n",
    "tm = ThoughtManager(note_db_path, \n",
    "                    model_name=model_name, \n",
    "                    save_path=save_path, \n",
    "                    device='cuda',\n",
    "                    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "thoughts = tm.note_db.thoughts.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = tm.note_db.cleaned_note.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Summarize the context in one short sentence.\\nContext: {}'''\n",
    "\n",
    "def summarize(text, prompt=prompt):\n",
    "    query = prompt.format(text)\n",
    "    return llm(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-11-30 01-48-47\\n\\n \\nКлассно было в универе не париться о том, что поправишься, о том что будешь тупой с утра. Просто бухаешь а потом идёшь на пары.\\n\\n '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A student is expressing frustration that they didn't bother to review their notes the night before and are now having to go to class without being prepared.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = '''Summarize the context in one short sentence.\\nContext: {}'''\n",
    "summarize(notes[0], prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-12-23 13-17-12\\n\\n \\nзабавно, что работу с обученными языковыми моделями можно сравнить с упрощением, потому что у самой модели нет никакой цели или глобального критерия правильности, кроме лоса, но вас не может нам помочь для решения задачи, на которую модель не была обучена.. это превращает inference или 0-shot модели в некоторое подобие укрощения или родео, где с помощью заправок и уговоров. Мы пытаемся заставить модели сделать то, что нам нужно.\\n\\n '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note = notes[10]\n",
    "note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'language, models, simplification, inference, task'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = '''Context: {}\\n Get 1-5 keywords for the context. Output ONLY keywords, split by a comma. Do NOT output anything else.'''\n",
    "llm(prompt.format(note))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [llm(prompt.format(note)) for note in notes[:30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "university, morning, classes, studying, habits 2022-11-30 01-48-47\n",
      "\n",
      " \n",
      "Классно было в универе не париться о том, что поправишься, о том что будешь тупой с утра. Просто бухаешь а потом идёшь на пары.\n",
      "\n",
      " \n",
      "photography, timeline, classification, images, sorting 2022-12-24 11-16-56\n",
      "\n",
      " \n",
      "Сайт с фотографиями, которые расположены в виде ленты. Сначала самая последняя потом по возрастанию возраста плюс, когда открываешь одну отдельную фотографию. Только ней подбираются наиболее похожи похожи стреляется базам случаев по среднему вектору, который получен с помощью обычного картона. Что-то типа разрезанная взять, а классификационная, чтобы получить распределение классов как бы.\n",
      "\n",
      " \n",
      "death, life, fear, suffering, happiness 2023-06-16 18-28-26\n",
      "\n",
      " \n",
      "Человек смерти боится, потому что жизнь любит вот как я понимаю. Итак, природа велела. Но это подло и тут весь обман жизнь есть боль жизни. Страх и человек несчастен. Теперь всё боль и страх. Теперь человек жизнь любит, потому что боль и страх любит и так сделали жизнь теперь даётся за более страх. И тут весь обман теперь человек ещё не тот человек будет новый Человек счастливый и гордый. Кому будет всё равно жить или не жить. Тот будет новый человек. Кто победит боль и страх тот сам Бог будет. \n",
      "\n",
      " \n",
      "psychological, armor, memory, faith, belief 2023-11-11 21-15-43\n",
      "\n",
      " \n",
      "помнить о доспехах, когда носишь психологический доспехи? Будь-то одежда маска верования убеждения и так далее села доспехов проявляется только когда о них помнишь. Если от этих доспехов забываешь, то они остаются лишь бессмысленной тряпкой и не работают. Поэтому для психологических доспехах необходимо они вспомнить. \n",
      "\n",
      " \n",
      "consciousness, clarity, understanding, reality, perception 2023-06-10 00-17-48\n",
      "\n",
      " \n",
      "Ну где же это ясность сознания, которая сопровождала меня ключевые моменты жизни, такие как Евпатория больше даже и не знаю, какие моменты были ключевыми. Пожалуй Евпатория соседа мехмате моменты стояния в курилке может быть поездки с одноклассниками, не встречи с универсальными друзьями. В такие моменты испытываешь какую-то ясность сознания и эту ясность так сложно иногда создать. Эта ясность мышления похоже на то, о чём говорил Йошуа Бенжио в своих высказываниях об его отношений с наукой периоды отчётливый ясностью сменяются периодами полного непонимания и дереализации науке либо жизни. Ответы на одни и те же вопросы могут казаться настолько очевидными в один момент, а в другой момент быть совершенно неразрешимыми, как же так, неужели действительно меняется объективная реальность или только субъективное восприятие. \n",
      "\n",
      " \n",
      "Planning, LLMs, Reasoning, Memory, Transformers 2023-11-01 12-32-21\n",
      "\n",
      " \n",
      "MB: planning is pretty bad for LLMs\n",
      "\n",
      "(https://cacm.acm.org/blogs/blog-cacm/276268-can-llms-really-reason-and-plan/fulltext?s=09)\n",
      "\n",
      "(https://arxiv.org/abs/2302.06706)\n",
      "\n",
      "What planning community did is rename the activities in Blocksworld. This very much affected the quality of LLM. Random names are even worse. It means  that LLMs learn a statistical model (world model) during pretraining. It we suppose that it has a model of the world, it is needed to plan a sequence of actions. These results show that maybe its not the case or LLM patterns are different from human ones. \n",
      "\n",
      "So maybe what LLM does is retrieve similar patterns from pre-training instead generalizing by learning rules. In order to do reasoning we need to shift pattern to pattern. \n",
      "\n",
      "This means that we can invent some architecture that is better with abstractions. It can result in a giant leap in capabilities. Actually the original memory transformer had this in mind when provided memory storage. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "logic, abstraction, consciousness, RLHF, cognition 2024-03-01 12-35-37\n",
      "\n",
      " \n",
      "необходимо выходить за пределы логики, общей и личной. за логикой в пространстве разума можно строить интуиции через совпадение смысла из разных областей сознания. не обязательно приземляясь эти смыслы в осознаваемым логику, главное - строить устойчивые комбинации которые сохраняются,  инварианты относительно преобразований между областями мышления. для этого нужна память как пространство, где возникают объекты, как-то следующие из цепочек физических атомов мышления. такие объекты по видимому можно сохранять в виде объемных текстов, которые занимаются без особого мышления, просто как поток сознания. \n",
      "\n",
      "часто построение таких абстракций - машин, перерабатывающих мышление, напоминает языковые модели, пробегающие по текстам и собирающие смыслы в хранилище. вот только там смыслы имеют довольно после назначение - предсказать будущее. возможно, более правильный вектор - как раз сознание абстракций, устойчивых к перемене входного текста.\n",
      "\n",
      "не по какому поводу собираются абстракции у реального человека? по совокупности биологических причин и ожидания будущих и прошлых вознаграждений от системы наград. \n",
      "\n",
      " системы напомнишь rlhf, но должна обучаться целям суммой модели, а не сомневаться из человеческих предпочтений. она оценивает генерации и состояния, возникающие в абстрактной рабочей памяти \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "risk, trust, self, calculation, adrenalin 2024-02-19 23-24-32\n",
      "\n",
      " \n",
      "нужно больше рисковать. \n",
      "риск это момент бессилия, непросчитанных обстоятельств. в этот момент нужно довериться себе, поверить, что ты можешь справиться со всеми проблемами по мере поступления. отсутствие риска может быть вызвано привычкой к глубокому расчету, оно делает вдумчивым и трусливым. справиться можно силой воли либо через адреналиновые занятия \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "knowledge, interface, telegram, bot, hashtags 2022-11-19 21-46-17\n",
      "\n",
      " \n",
      "Идея сделать взаимодействие с базы знаний с интерфейсом через телеграм бота, например, найти все заметки по данному Хэштегу или идея найти все заметки похожую на данную.\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Ideas, Money, Power, Honor, Worth 2023-01-16 11-00-05\n",
      "\n",
      " \n",
      "Интересная идея состоит в том, что вместо денег либо материальных ценностей, которые можно давать человеку за труд, существует другая субстанция, которая также может его вознаграждать.\n",
      "\n",
      "Такой субстанцей является почёт либо власть. почёт или власть не всегда связаны с деньгами напрямую, подтверждением тому могут служить люди обладающие почётным званием но маленьким состоянием.\n",
      "\n",
      " \n",
      "языковые, модели, упрощение, inference, обучены 2022-12-23 13-17-12\n",
      "\n",
      " \n",
      "забавно, что работу с обученными языковыми моделями можно сравнить с упрощением, потому что у самой модели нет никакой цели или глобального критерия правильности, кроме лоса, но вас не может нам помочь для решения задачи, на которую модель не была обучена.. это превращает inference или 0-shot модели в некоторое подобие укрощения или родео, где с помощью заправок и уговоров. Мы пытаемся заставить модели сделать то, что нам нужно.\n",
      "\n",
      " \n",
      "innovation, progress, winner, mentality, science, intelligence, talent, motivation, PhD 2023-07-27 11-57-32\n",
      "\n",
      " \n",
      "Pavel Osinenko:\n",
      "You will never make something absolutely innovative, that's impossible, the humanity makes progress with small steps. A winner is someone who is mentally stable and patient enough not to give up and work hard \n",
      "\n",
      "Georgy Malaniya:\n",
      "Тезис 1: я никогда не пойду на галеру\n",
      "Я буду ебашить за стипендию до тех пор пока не дожму то, что будет давать возможность жить тем, что дает мне сил жить\n",
      "\n",
      "Тезис 2: холодный или горячий старт ничего не решает\n",
      "В долгосроке будет какая то дельта возможно, но она будет со временем очень мала. Все решает исключительно труд, это я для себя точно уяснил\n",
      "\n",
      "Нет смысла думать о достижениях на школьных олимпиадах, студенческих паперах \n",
      "Самый настоящий спорт начинается после пхд\n",
      "\n",
      "Когда у тебя нет облиг, когда развязаны руки, есть степень и бэкап в виде галеры на которую можно уйти за 300к наносек\n",
      "\n",
      "\n",
      "Вообще один из самых больших приколов науки это что можно стать ебать рок звездой на самом деле, если ты +- обладаешь интеллектом и талантом ебашить в нужном направлении. \n",
      "в последнее время часто стал встречать на конфах и просто в работах челов, которые ну просто охуеть) почитал вот диссер ilya sutskever, (который кста chatgpt лидил и в cv тоже много чего сделал) и у него в год по 4-5 статей на топовых конференциях и так 5 лет PhD) ну это как пример просто. \n",
      "У тебя тоже есть какое-то внутреннее охуевание от таких челов? Иногда такое мотивирует а иногда наоборот понимаешь, что ты как бы на более холодном старте что ли и вообще мб тогда уйти умирать в условный сбер на лидовскую зп и не ебать мозг?) Чо думаешь по этому поводу, бывает ли,как справляешься\n",
      "\n",
      " \n",
      "data, memory, recurrence, Revell, generation 2023-06-19 20-43-25\n",
      "\n",
      " \n",
      "По сути, задачи поиска похожие заметки или нескольких похожих заметок в базе данных и дальнейшей генерация ответа или продолжение текущее заметки на основании подобранного очень похоже на модели Revell модели. Каким-то образом нужно понять, как в эту парадигму устроить идею рекуррентный памяти, в чём же смысл рекуррентно сти в чём её преимущества перед римом и как их совместить. \n",
      "\n",
      " \n",
      "ideas, memory, communication, travel, simplicity 2023-07-17 12-55-04\n",
      "\n",
      " \n",
      "Мысли Шри Ланка\n",
      "\n",
      "- пространство человеческих идей непрерывно и задаётся кучей параметров, любые дискретные явления в нем вроде пересечения и комбинации идей - просто явные области непрерывных эффектов\n",
      "- ощущения с нескольких моментов складываются в одно осознанное восприятие.  их связывает память - способ передачи информации из прошлых в текущее восприятие. информация может передаваться на разных уровнях и областях восприятия - запахи, смутное ощущение, сочетание букв, паттерны, цвет, ... также информация из памяти может быть частью текущего восприятия.\n",
      "- поставлена задача перестать испытывать неловкость при ненапряжном общении с незнакомцами. в частности принять несогласия и недопонимания, это норма.\n",
      "+ общение с малым кругом людей и постоянное следование желаемому приводит к внутренней капризности, сложности разрешать, отпускать нежелаемое\n",
      "- новозеландцы - летчик с красными глазами и девушка, познакомившиеся на Бали \n",
      "- каноничный австралиец - акцент, mate, got sooo drunk last night, телосложение, серф\n",
      "- когда едешь в отпуск, в какой-то момент переступаешь материалистический барьер и отпускаешь расходы. нужно как можно быстрее это делать, чтобы переходить полностью в состояние отпуска\n",
      "- память это временной ряд со своими зависимостями, сезонностями, трендами. есть шумные зависимости, приближаемые законами связи с прошлым. моделировать связь между прошлым и будущим как временной ряд?\n",
      "- Фейнман - няшка (в научном смысле)\n",
      "- в каждый момент времени ты как агент представляешь себя в разных состояниях и составляешь возможные действия\n",
      "- кальянщик на самом деле выполняет работу фильтра от самого тяжёлого в калике\n",
      "- почему-то оно не отпускает. кажется, что если развяжешь все узелки, то должно отпустить. может, не все узелки развязаны? надо копнуть глубже, в детство или нетривиальное. например, в совсем базовые эмоции посмотреть, их причины.\n",
      "- вот некоторым вещам просто не суждено случиться. более того, они замечательны именно этим. например, дружественные отношения с кем-то из туризма, близкое к дружескому общению с незнакомцами\n",
      "- какая-то глубокая неловкость из-за неумелого общения что ли, что в развлекательном, что в научном плане. нужна видимо какая-то простота в подборе и отпускании людей\n",
      "- ещё одна причина - накатывающее ощущение своих недостатков. это только усугубляет воронку\n",
      "- возможно, все чувства воронки это на самом деле одно, которое никак не даётся сознанию. вот ближе всего - чувство страха потери\n",
      "- может ли мозг ходить по мысленным тропам, не появившимся до этого в подсознании? постоянно ли подсознание работает? отдельная ли это часть мозга или это слишком сильное название \n",
      "\n",
      " \n",
      "marketing, information, technology, development, humanity 2023-09-15 18-26-26\n",
      "\n",
      " \n",
      "по маркетингу фото для заметок развитие человечества очень сильно зависит от передачи информации из поколения в поколение, а также от способов сохранения и организации этой информации. По большей части люди стали жить намного лучше. Когда стали появляться источники и средства хранения информации, которые позволили сделать технологический прорыв. Теперь можно посмотреть на средства хранения информации сейчас и их развития и сделать из этого вывод, что они несовершенны и способом качества технологического прорыва. Будет изобретение нового способа хранения передачи организации и анализа информации. \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "children, mother, door, car, open 2023-06-16 18-36-37\n",
      "\n",
      " \n",
      "прохожу мимо женщины с детьми, которые садятся в машину. Дети дёргают ручку двери. Дверь не открывается. Подходят мама говорит, да она открыта. Потом открывает машину, и дети открывают двери так вот вопрос, какого х. \n",
      "\n",
      " \n",
      "systems, cooperation, project, motivation, synergy 2023-08-20 00-18-19\n",
      "\n",
      " \n",
      "системы, где общая цель выгодна каждому из элементов работают лучше всего. Примером такой системы может быть проект, в котором каждый из участников получает выгоду от сотрудничества свою либо сюжет фильма, где мотивация каждого из персонажей способствует развитию сюжета. \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "осознанность, философия, буддизм, настройка, выбор 2022-11-27 18-14-28\n",
      "\n",
      " \n",
      "майндсет роста напрямую связан с идеей осознанностью философии осознанности и буддизма в сети просто целью является настройка себя на увеличение выброса от сложности выполняемого действия это очень похоже на идею того чтобы жить настоящим то есть проживать каждый момент чувствовать его максимально полно потому что чувствовать и есть увеличить выработку дофамина от каждого рецептора\n",
      "\n",
      " \n",
      "control, attention, productivity, marketing, media 2023-08-10 11-27-40\n",
      "\n",
      " \n",
      "Итак, идея для инструмента контроля внимание контроль внимания. Это супер важно, потому что это самый важный ресурс, который есть у тебя для продуктивности за ним охотятся все, кому ты нужен как потребитель, то есть реклама продуктов, услуг и так далее На это направленные силы маркетологов. Идея состоит в том, чтобы получать только необходимые полезные фичи от продуктов, не попадая под отрицательное влияние. Для этого необходимо создать собственную ленту новостей во-первых и во-вторых перейди, например, чтобы использовать социальные сети и информационные источники более эффективно. Поэтому необходимо добавить ещё и полезные привычки, чтобы сформировать способ взаимодействия с медиа, который будет выгоден для тебя, а не для кого-то ещё. \n",
      "\n",
      " \n",
      "bot, skill, evening, article, Wikipedia, education, science 2022-11-22 22-09-47\n",
      "\n",
      " \n",
      "Добавить для бота навык каждый вечер отправлять, что-то полезное, например, статью из Википедии или научную статью для постоянного образования.\n",
      "\n",
      " \n",
      "friends, motivate, know, spirit, own 2023-05-29 21-27-23\n",
      "\n",
      " \n",
      "Не обязательно познавать мир с друзьями, которые максимально близкими к тебе по духу. Достаточно просто найти тех, кто мотивирует тебя, познавать и делать собственные выводы. \n",
      "\n",
      " \n",
      "Neural network, Sigmoid function, Activation function, Full connection, Telegram 2023-02-20 18-55-56\n",
      "\n",
      " \n",
      "для лекции рассказать про нейронную сеть, полносвязную с сигмоидой как функцию активации. сигмоида-это сжимающая отображение и у любого нажимающего отображения. Есть неподвижная точка На практике получается, что если сигмоиду применить много раз, то она как-раз и сжимает это отображение в свою неподвижную точку. Пример есть в телеграме.\n",
      "\n",
      " \n",
      "family, value, optimization, economics, society 2023-12-15 12-27-41\n",
      "\n",
      " \n",
      "Семья и экономика интересно посмотреть на семью с точки зрения той ценности, которую она пытается оптимизировать, то есть семейного излишка. Это такой набор ценности, которые аккумулируются в семье и которая не аккумулировать бы в случае её отсутствия с развитием общество накапливать ценность и существовать отдельно становилось всё проще, что приводило к большей атомизации семьи, То есть семья становятся более атомарной и необязательно иметь хозяйства из большого количества людей, чтобы себя прокормить, задумываться. Теперь стоит насколько семья и конкретные люди помогают увеличивать стоимость семей. Прибавят ли этой стоимости добавления нового человека в эту семью или наоборот убавить стоимость же. Это может выражаться не только в чём-то материальном, но и в благосостоянии в целом. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "train, Arab, lab, university, communication 2023-06-10 00-18-37\n",
      "\n",
      " \n",
      "сидел сегодня в электричке после пикника с лабораторией Ксюша и рами разговаривали на арабском раме или него это родной язык, а Ксюша учила его в университете. Я испытал какое-то поразительное чувство я сидел и смотрел на них с открытым ртом. Это было так странно и чудесно видеть эту коммуникацию ощущать, что происходит, что-то связывающие людей национальности разного происхождения не говорят на языке. Этот язык совершенно непонятен не могут быть законы, которые совершенно отличаются от языка, на котором ты говоришь. Может быть этот язык даже приводит тебя в разные места совершенно другие места, отличные от тех, которые тебе разрешен доступ. Эти истории прекрасно. \n",
      "\n",
      " \n",
      "machine learning, метрики, пространство, расстояние, свойста 2023-10-18 19-47-31\n",
      "\n",
      " \n",
      "Пространство и метрики в машинном обучении мне уже довольно давно захватывает Идея о том, что классическое метрическое пространство, в частности, Евклидова, которые мы используем для машинного обучения, может быть не идеально в каких--то ситуациях. Вот, например, на воркшопе Huawei мой институтский преподаватель Иванов выступал с докладом о том, что можно использовать необычное расстояние, чтобы лучше разделять карте. Мне кажется, это довольно банально примером, но в целом хотелось бы подумать над свойствами расстояние в целом и применимости этих свойств к пространством скрытых представлений в машинном обучении. Это может помочь более правильно находиться отношения между объектами в этих пространствах, если мы знаем какие-то свойства. \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "life, calm, basketball, relaxed, moment 2023-03-27 11-27-31\n",
      "\n",
      " \n",
      "быть спокойным и размеренным в любой момент. как в баскетболе, ты ведёшь жизнь а не наоборот \n",
      "\n",
      " \n",
      "Artificial Intelligence, Access, Speed, Applications, Knowledge Base 2023-03-19 09-53-39\n",
      "\n",
      " \n",
      "Надо сделать прикладное искусственный интеллект максимально быстрым для доступа, чтобы можно было вот таким же образом, как я сейчас говорю получать к нему доступ и менять его режимы между поиском по сети генеративным ответом и ответом на основание базы знаний. Собственный и у этой системы более ограничены множество область применимости, поэтому поэтому к ней и требования меньше, чем к общему искусственному интеллекту.\n",
      "\n",
      " \n",
      "ceal, purpose, consciousness, outside, movement 2023-07-20 11-07-01\n",
      "\n",
      " \n",
      "Когда мы говорим о цели, почему-то подразумевается о том, что она находится в из вне человеческого сознания, хотя вроде бы очевидно, что наоборот цель по определению — это то, куда движется человеческое сознание?\n",
      "\n",
      " \n",
      "Money, happiness, freedom, self-discovery, purpose 2023-09-17 01-29-54\n",
      "\n",
      " \n",
      "Ролики пьюдипая это, по сути, очень похоже на то, чем бы ты занимался Будете тебя бесконечное количество денег и просто возможно сделать всё чего ты хочешь. Это очень хорошо показывает тебе чего ты? Почему тебя реально тянет? Я же интересно смотреть на человека, который реально не подвластен стремлению работать у него есть куча потенциальные возможности. Единственная твоя задача жизнь в соответствии с принципами, которые у тебя есть и совместить желание тебя и твоих близких людей. Это так странно и одновременно прикольно, и пожалуй позволяет открыть себя максимально как человека. \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "finance, idea, entrepreneurship, coding, income 2023-04-22 20-55-52\n",
      "\n",
      " \n",
      "Нужно искать финансовую идеи очень близко к своей основной деятельности. В таком случае можно будет минимальными затратами получать дополнительный доход, то, что у кого-то заняло бы много времени на реализацию. У тебя может занять несколько вечеров кодинга. \n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for k, n in zip(keywords, notes):\n",
    "    print(k, n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_neural",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
